{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69df07e-61dd-49d4-9d27-bf332f8a5e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID b6e4584a48fd46d581867e8c8f27f3b1 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m52\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Start an MLflow experiment and log initial parameters\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     33\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     34\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:298\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    296\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    299\u001b[0m         (\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    304\u001b[0m     )\n\u001b[0;32m    305\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID b6e4584a48fd46d581867e8c8f27f3b1 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from mlflow import MlflowClient, tracking\n",
    "import mlflow\n",
    "# Connect to the MLflow Tracking Server\n",
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "\n",
    "# Define paths and read data\n",
    "zip_file_path = r\"D:\\SirWaqas\\forest+fires.zip\"\n",
    "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "    with zip_ref.open(\"forestfires.csv\") as csv_file:\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "# Preprocess data\n",
    "df.month.replace((\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"), (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), inplace=True)\n",
    "df.day.replace((\"mon\", \"tue\", \"wed\", \"thu\", \"fri\", \"sat\", \"sun\"), (1, 2, 3, 4, 5, 6, 7), inplace=True)\n",
    "scale_columns = [\"X\", \"Y\", \"month\", \"day\", \"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\", \"rain\"]\n",
    "scaler = StandardScaler()\n",
    "df[scale_columns] = scaler.fit_transform(df[scale_columns])\n",
    "\n",
    "# Configure and build the model\n",
    "X = df.drop(\"area\", axis=1)\n",
    "y = df[\"area\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=52)\n",
    "\n",
    "# Start an MLflow experiment and log initial parameters\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"n_features\", X.shape[1])\n",
    "    mlflow.log_param(\"epochs\", 100)\n",
    "    mlflow.log_param(\"batch_size\", 13)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(X.shape[1], input_dim=X.shape[1], activation=\"relu\"),\n",
    "        Dense(X.shape[1] // 2, activation=\"relu\"),\n",
    "        Dense(X.shape[1] // 2, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train the model and log metrics\n",
    "    history = model.fit(\n",
    "        X_train, y_train, validation_split=0.1, epochs=100, batch_size=13\n",
    "    )\n",
    "    mlflow.log_metric(\"train_loss\", history.history[\"loss\"][-1])\n",
    "    mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][-1])\n",
    "\n",
    "# Register the model and save metrics as artifacts\n",
    "model.save(\"forest_fire_model.h5\")\n",
    "mlflow.log_artifact(\"forest_fire_model.h5\", \"mlflow_models\")\n",
    "\n",
    "# Evaluate the model and log additional metrics\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mlflow.log_metric(\"test_mse\", mse_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.flatten()\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mlflow.log_metric(\"test_r2\", r2)\n",
    "\n",
    "# Load the model as a PyFunc model\n",
    "loaded_model = mlflow.pyfunc.load_model(\"forest_fire_model.h5\")\n",
    "\n",
    "# Make predictions on a new DataFrame\n",
    "new_data = pd.DataFrame({\"X\": 10, \"Y\": 20, \"month\": 5, \"day\": 2, \"FFMC\": 30, \"DMC\": 40, \"DC\": 50,\n",
    "                         \"ISI\": 60, \"temp\": 70, \"RH\": 80, \"wind\": 90, \"rain\": 0})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
